import os
import glob
import streamlit as st

from dotenv import load_dotenv
load_dotenv()

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.documents import Document


# -----------------------------
# Streamlit basic configst
# -----------------------------
st.set_page_config(page_title="ì›Œí™€ RAG ì±—ë´‡", page_icon="ğŸŒ", layout="wide")
st.title("ğŸŒ ì›Œí™€ ì±—ë´‡")
st.caption("ì›Œí‚¹í™€ë¦¬ë°ì´ ì¸í¬ì„¼í„° ë¬¸ì„œ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ê³ , ê¸°ì¤€ ê¸°ë°˜ ì¶”ì²œì„ ì œê³µí•©ë‹ˆë‹¤.")


# -----------------------------
# Data config
# -----------------------------
BASE_DATA_DIR = "data"

COUNTRY_MAP = {
    "ğŸ‡¦ğŸ‡º í˜¸ì£¼": "australia",
    "ğŸ‡¨ğŸ‡¦ ìºë‚˜ë‹¤": "canada",
    "ğŸ‡¯ğŸ‡µ ì¼ë³¸": "japan",
    "ğŸ‡³ğŸ‡¿ ë‰´ì§ˆëœë“œ": "newzealand",
    "ğŸ‡©ğŸ‡ª ë…ì¼": "germany",
}


# -----------------------------
# ì¶”ì²œ ê¸°ì¤€ & ì ìˆ˜í‘œ
# -----------------------------
CRITERIA = {
    "income": "ìˆ˜ì…/ì„ê¸ˆ",
    "settlement": "ì´ˆê¸° ì •ì°© ë‚œì´ë„",
    "language": "ì–¸ì–´ ì¥ë²½",
    "visa": "ë¹„ì ì•ˆì •ì„±/ì—°ì¥",
    "culture": "ë¬¸í™”Â·ìƒí™œ ì ì‘ë„",
}

BASE_SCORE = {
    "australia": {
        "income": 5,
        "settlement": 3,
        "language": 2,
        "visa": 4,
        "culture": 3,
    },
    "japan": {
        "income": 2,
        "settlement": 4,
        "language": 4,
        "visa": 3,
        "culture": 5,
    },
}


# -----------------------------
# Helpers
# -----------------------------
def load_all_documents(base_dir: str) -> list[Document]:
    docs = []
    for root, _, files in os.walk(base_dir):
        for fname in files:
            if not fname.endswith(".txt"):
                continue

            fp = os.path.join(root, fname)
            with open(fp, "r", encoding="utf-8") as f:
                text = f.read().strip()

            parts = os.path.normpath(fp).split(os.sep)
            country = parts[1] if len(parts) > 1 else "unknown"

            docs.append(
                Document(
                    page_content=text,
                    metadata={
                        "source_file": fname,
                        "country": country,
                        "full_path": fp,
                    },
                )
            )
    return docs


def format_context(docs: list[Document]) -> str:
    blocks = []
    for i, d in enumerate(docs, 1):
        src = d.metadata.get("source_file", "unknown.txt")
        blocks.append(f"[ê·¼ê±°{i} | {src}]\n{d.page_content}")
    return "\n\n---\n\n".join(blocks)


def priority_to_weight(p1, p2, p3):
    weights = {k: 0 for k in CRITERIA.keys()}
    weights[p1] = 3
    weights[p2] = 2
    weights[p3] = 1
    return weights


def calc_country_score(country_key: str, weights: dict) -> int:
    return sum(BASE_SCORE[country_key][k] * w for k, w in weights.items())


# -----------------------------
# LLM / Vectorstore
# -----------------------------
def get_llm():
    return ChatOpenAI(model="gpt-4o-mini", temperature=0.2)


def get_embeddings():
    return OpenAIEmbeddings(model="text-embedding-3-small")


@st.cache_resource
def build_global_vectorstore():
    docs = load_all_documents(BASE_DATA_DIR)

    splitter = RecursiveCharacterTextSplitter(
        chunk_size=900,
        chunk_overlap=150,
        separators=["\n\n", "\n", "-", "â€¢", " ", ""],
    )
    chunks = splitter.split_documents(docs)
    return FAISS.from_documents(chunks, get_embeddings())


vectorstore = build_global_vectorstore()
retriever = vectorstore.as_retriever(search_kwargs={"k": 5})
llm = get_llm()


# -----------------------------
# Sidebar UI
# -----------------------------
with st.sidebar:
    st.subheader("âš™ï¸ ì„¤ì •")

    country_label = st.selectbox("êµ­ê°€ ì„ íƒ", list(COUNTRY_MAP.keys()), index=0)
    country_key = COUNTRY_MAP[country_label]

    st.markdown("---")
    st.subheader("ğŸ êµ­ê°€ ì¶”ì²œ ê¸°ì¤€ (ìš°ì„ ìˆœìœ„)")

    p1 = st.selectbox(
        "1ï¸âƒ£ ê°€ì¥ ì¤‘ìš”í•œ ê¸°ì¤€",
        list(CRITERIA.keys()),
        format_func=lambda x: CRITERIA[x],
    )

    p2 = st.selectbox(
        "2ï¸âƒ£ ë‘ ë²ˆì§¸ ê¸°ì¤€",
        [k for k in CRITERIA.keys() if k != p1],
        format_func=lambda x: CRITERIA[x],
    )

    p3 = st.selectbox(
        "3ï¸âƒ£ ì„¸ ë²ˆì§¸ ê¸°ì¤€",
        [k for k in CRITERIA.keys() if k not in (p1, p2)],
        format_func=lambda x: CRITERIA[x],
    )

    show_context = st.checkbox("ê·¼ê±°(Context) ë³´ê¸°", value=False)


# -----------------------------
# Chat state
# -----------------------------
if "messages" not in st.session_state:
    st.session_state.messages = [
        {
            "role": "assistant",
            "content": f"{country_label} ì›Œí™€ ê´€ë ¨í•´ì„œ ê¶ê¸ˆí•œ ê±° ë¬¼ì–´ë´!",
        }
    ]

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])


# -----------------------------
# Chat input
# -----------------------------
user_q = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: í˜¸ì£¼ vs ì¼ë³¸ ì¶”ì²œ)")
if user_q:
    st.session_state.messages.append({"role": "user", "content": user_q})
    with st.chat_message("user"):
        st.markdown(user_q)

    docs = retriever.invoke(user_q)
    context = format_context(docs)

    # ğŸ”¥ ì¶”ì²œ ì§ˆë¬¸ ê°ì§€
    is_recommend = any(k in user_q for k in ["ì¶”ì²œ", "ì–´ë””", "ë¹„êµ"])

    with st.chat_message("assistant"):
        with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):

            if is_recommend:
                weights = priority_to_weight(p1, p2, p3)
                au_score = calc_country_score("australia", weights)
                jp_score = calc_country_score("japan", weights)

                recommended = "í˜¸ì£¼" if au_score > jp_score else "ì¼ë³¸"

                prompt = f"""
ë‹¹ì‹ ì€ ì›Œí‚¹í™€ë¦¬ë°ì´ ì „ë¬¸ ìƒë‹´ê°€ì…ë‹ˆë‹¤.

[ì‚¬ìš©ì ìš°ì„ ìˆœìœ„]
1ìˆœìœ„: {CRITERIA[p1]}
2ìˆœìœ„: {CRITERIA[p2]}
3ìˆœìœ„: {CRITERIA[p3]}

[êµ­ê°€ë³„ ì ìˆ˜]
- í˜¸ì£¼: {au_score}
- ì¼ë³¸: {jp_score}

[Context]
{context}

[Instruction]
- ì ìˆ˜ì™€ ë¬¸ì„œ ê·¼ê±°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ
- ì™œ {recommended}ê°€ ë” ì í•©í•œì§€ ì„¤ëª…í•˜ì„¸ìš”
- ë‹¨ì •í•˜ì§€ ë§ê³  ì¡°ê±´ë¶€ ì¶”ì²œìœ¼ë¡œ ë§ˆë¬´ë¦¬í•˜ì„¸ìš”
"""
            else:
                prompt = f"""
ë‹¹ì‹ ì€ ì›Œí‚¹í™€ë¦¬ë°ì´ ì¤€ë¹„ë¥¼ ë•ëŠ” ì „ë¬¸ ìƒë‹´ ì±—ë´‡ì…ë‹ˆë‹¤.

[Country]
{country_label}

[Context]
{context}

[User Question]
{user_q}
"""

            resp = llm.invoke(prompt)
            answer = resp.content

        st.markdown(answer)

        if show_context:
            st.markdown("### ğŸ” ê·¼ê±°(Context)")
            st.code(context)

    st.session_state.messages.append({"role": "assistant", "content": answer})
